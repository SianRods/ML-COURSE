{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicing Implementation of Gradient Descent Algorithm for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the same two data points as before - a house with 1000 square feet sold for \\\\$300,000 and a house with 2000 square feet sold for \\\\$500,000.\n",
    "\n",
    "| Size (1000 sqft)     | Price (1000s of dollars) |\n",
    "| ----------------| ------------------------ |\n",
    "| 1               | 300                      |\n",
    "| 2               | 500                      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array([1,2])  #size of houses in square-feet\n",
    "Y_train=np.array([300,500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding how the algorithm actually works \n",
    "1. First we split the data into x_train and y_train\n",
    "2. Total of 4 Functions are needed : To `compute_function(x,w,b)`,`cost_funct(x_vec,y-vec,b,w)`,`gradient(x_vec,y_vec,w,b)`,`descent_algo(x,y,learning_rate)`\n",
    "3. All these functions are must and must be executed as specified \n",
    "4. Plotting the learning curve if also important to understand whether Gradient Descent Algorithm is working properly \n",
    "5. Learning rate can be set by analysing the Learning Curve and it's variation \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Prediction Function \n",
    "def compute_function(x,w,b):\n",
    "    f_wb=x*w+b\n",
    "    return f_wb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Cost-Function\n",
    "def cost_function(x,y,w,b):\n",
    "    # Initilising with the initial value of w and b \n",
    "    # w_init=0\n",
    "    # b_init=0\n",
    "    # Declaring the size of the Tuple \n",
    "    m=x.shape[0]\n",
    "    f_wb=np.zeros(m)\n",
    "    cost=0.0\n",
    "    for i in range(m):\n",
    "        f_wb[i]=compute_function(x[i],w,b)\n",
    "        temp=(f_wb[i]-y[i])**2\n",
    "        temp=temp/(2*m)\n",
    "        cost = cost+ temp\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing a Seperate Method to calculate Gradient for given parameters** \\\n",
    "This is Because the gradient descent algorithm calculate the derivative with updated parameters for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the Gradient \n",
    "def gradient(x,y,w,b):\n",
    "    df_dw=0\n",
    "    df_db=0\n",
    "    # We want the floating point representation\n",
    "    m=x.shape[0]\n",
    "\n",
    "    for i in range(m):\n",
    "        df_dw_i=(((compute_function(x[i],w,b))-y[i])*x[i])/m\n",
    "        df_db_i=(((compute_function(x[i],w,b))-y[i]))/m\n",
    "        df_dw += df_dw_i\n",
    "        df_db += df_db_i\n",
    "    der=[df_dw,df_db]\n",
    "    return der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Implementing the Gradient Descent Algorithm\n",
    "def gradient_descent(x,y,alpha):\n",
    "    # w=w-alphe*df_dw\n",
    "    # b=b-alphe*df_db\n",
    "    w_init=0\n",
    "    b_init=0\n",
    "    # Using the Standad Value of Epsilon For iterations \n",
    "    for i in range(1000):\n",
    "        temp_w=w_init- alpha*gradient(x,y,w_init,b_init)[0]\n",
    "        temp_b=b_init- alpha*gradient(x,y,w_init,b_init)[1]\n",
    "        w_init=temp_w\n",
    "        b_init=temp_b\n",
    "\n",
    "    return w_init,b_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "(np.float64(199.9930208199552), np.float64(100.01129255052611))\n"
     ]
    }
   ],
   "source": [
    "print(type(gradient_descent(X_train,Y_train,0.1)))\n",
    "print(gradient_descent(X_train,Y_train,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.427926384502476e-06\n"
     ]
    }
   ],
   "source": [
    "w_final=gradient_descent(X_train,Y_train,0.1)[0]\n",
    "b_final=gradient_descent(X_train,Y_train,0.1)[1]\n",
    "print(cost_function(X_train,Y_train,w_final,b_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 sqft house prediction 300.0 Thousand dollars\n"
     ]
    }
   ],
   "source": [
    "print(f\"1000 sqft house prediction {w_final*1.0 + b_final:0.1f} Thousand dollars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
