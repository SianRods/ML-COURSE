{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the Multivariable-Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as ply\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_2\"></a>\n",
    "\n",
    "You will use the motivating example of housing price prediction. The training dataset contains three examples with four features (size, bedrooms, floors and, age) shown in the table below.  Note that, unlike the earlier labs, size is in sqft rather than 1000 sqft. This causes an issue, which you will solve in the next lab!\n",
    "\n",
    "| Size (sqft) | Number of Bedrooms  | Number of floors | Age of  Home | Price (1000s dollars)  |   \n",
    "| ----------------| ------------------- |----------------- |--------------|-------------- |  \n",
    "| 2104            | 5                   | 1                | 45           | 460           |  \n",
    "| 1416            | 3                   | 2                | 40           | 232           |  \n",
    "| 852             | 2                   | 1                | 35           | 178           |  \n",
    "\n",
    "You will build a linear regression model using these values so you can then predict the price for other houses. For example, a house with 1200 sqft, 3 bedrooms, 1 floor, 40 years old.  \n",
    "\n",
    "Please run the following code cell to create your `X_train` and `y_train` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "X_train=np.array([[2104,5,1,45],  # Training Set Number -1\n",
    "                 [1416,3,2,40], # Training set Number -2 \n",
    "                 [852,2,1,35]])  # Training set Number -3\n",
    " \n",
    "Y_train=np.array([460,232,178])\n",
    "#  We have to treat the Whole Operation Like Two-Dimensional Array i and j \n",
    "print(X_train[1,2]) # Operations of 2-Dimensional Arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the compute_function \n",
    "def compute_function(x,w,b):\n",
    "    f_wb=np.dot(x,w) +b\n",
    "    return f_wb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that here the parameter `x` and `w `passed represents Vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the compute_cost\n",
    "def compute_cost(x,y,w,b):\n",
    "    m=x.shape[0]\n",
    "    cost=0.0\n",
    "    for i in range(m):\n",
    "        temp_i=((np.dot(x[i],w)+b)-y[i])**2\n",
    "        cost += temp_i\n",
    "    cost = cost/(2*m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important Point (Added whole code for all three functions to the notebook) :\n",
    "for j in range(n):                         \n",
    "            `dj_dw[j] = dj_dw[j] + err * X[i, j]`    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Calculating the Derivatives Vector \n",
    "def gradient_cal(x,y,w,b):\n",
    "# df_dw --> Will be a vector \n",
    "# df_db --> will be a number (floating point )\n",
    "\n",
    "# X_train= [[2104,5,1,45](i=0),[1416,3,2,40](i=1), [852,2,1,35](i=2)]\n",
    "# m=3\n",
    "# n=4\n",
    "# w = [w1 w2 w3 w4]\n",
    "# y = [y1 y2 y3 ]\n",
    "\n",
    "\n",
    "    df_db=0.0 \n",
    "    n=x.shape[1]\n",
    "    m=x.shape[0]\n",
    "    df_dw=np.zeros((n,))   # Initializing the List with required size to avoid the error\n",
    "\n",
    "    for i in range(m):\n",
    "        common_part = (compute_function(x[i],w,b) -y[i])\n",
    "        for j in range(n):\n",
    "            df_dw[j]+=common_part*x[i,j]  # This denotes an Element not any other thing\n",
    "        df_db += common_part\n",
    "        \n",
    "    df_dw=df_dw/m\n",
    "    df_db=df_db/m\n",
    "\n",
    "    return df_dw,df_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Gradient Descent Algorithm\n",
    "def descent_algo(x,y,learning_rate,iterations):\n",
    "\n",
    "    m=x.shape[0]\n",
    "    n=x.shape[1]\n",
    "    w_init = np.array([0,0,0,0])\n",
    "    b_init=0.0\n",
    "\n",
    "    for i in range(iterations):\n",
    "        dj_dw,dj_db=gradient_cal(x,y,w_init,b_init)\n",
    "        temp_w=w_init - (learning_rate * dj_dw)\n",
    "        temp_b=b_init - (learning_rate * dj_db)\n",
    "        w_init=temp_w # Here we are updating a list and not any single variable \n",
    "        b_init=b_init\n",
    "   \n",
    "    return w_init,b_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Values using the gradient Descent Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sian\\AppData\\Local\\Temp\\ipykernel_22020\\790436643.py:21: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  df_dw[j]+=common_part*x[i,j]  # This denotes an Element not any other thing\n",
      "C:\\Users\\Sian\\AppData\\Local\\Temp\\ipykernel_22020\\2342113286.py:11: RuntimeWarning: invalid value encountered in subtract\n",
      "  temp_w=w_init - (learning_rate * dj_dw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Optimized Values for W(weight): [nan nan nan nan] The Optimised Value for b(bias) : 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The Optimized Values for W(weight): {descent_algo(X_train,Y_train,0.001,10000)[0]} The Optimised Value for b(bias) : {descent_algo(X_train,Y_train,0.001,10000)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.21109467e+06 5.07833333e+03 1.83533333e+03 5.65733333e+04]\n",
      "[nan nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sian\\AppData\\Local\\Temp\\ipykernel_22020\\2292124465.py:21: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  df_dw[j]+=common_part*x[i,j]  # This denotes an Element not any other thing\n",
      "C:\\Users\\Sian\\AppData\\Local\\Temp\\ipykernel_22020\\3887814363.py:11: RuntimeWarning: invalid value encountered in subtract\n",
      "  temp_w=w_init- (learning_rate * dj_dw)\n"
     ]
    }
   ],
   "source": [
    "print(gradient_cal(X_train,Y_train,np.array([1,2,3,4]),34)[0])\n",
    "print(descent_algo(X_train,Y_train,0.001,1000)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[460 232 178]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-4.78297333e+05, -1.10733333e+03, -3.63333333e+02, -1.19500000e+04]), np.float64(-287.0))\n"
     ]
    }
   ],
   "source": [
    "print(gradient_cal(X_train,Y_train,np.zeros(4),3))  # Method has no problems at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.31298777e+86 -1.68291368e+84 -5.91385887e+83 -1.85074783e+85]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "w_opt,b_opt=descent_algo(X_train,Y_train,0.01,20)\n",
    "print(w_opt)\n",
    "print(b_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.20396437  0.0037492  -0.01124879 -0.06586307]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Probelm while running the Algorith for more than 100 iterations\n",
    "w_opt,b_opt=descent_algo(X_train,Y_train,0.0000005,1000)\n",
    "print(w_opt)\n",
    "print(b_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There is a issue when I keep the learning rate equal to = 0.1 and iterations are more than 100\n",
    "# But when learning rate is 0.0000005 and i keep iterations = 10000 eveything seems to work fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
