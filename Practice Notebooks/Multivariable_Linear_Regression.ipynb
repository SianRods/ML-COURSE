{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the Multivariable-Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as ply\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_2\"></a>\n",
    "\n",
    "You will use the motivating example of housing price prediction. The training dataset contains three examples with four features (size, bedrooms, floors and, age) shown in the table below.  Note that, unlike the earlier labs, size is in sqft rather than 1000 sqft. This causes an issue, which you will solve in the next lab!\n",
    "\n",
    "| Size (sqft) | Number of Bedrooms  | Number of floors | Age of  Home | Price (1000s dollars)  |   \n",
    "| ----------------| ------------------- |----------------- |--------------|-------------- |  \n",
    "| 2104            | 5                   | 1                | 45           | 460           |  \n",
    "| 1416            | 3                   | 2                | 40           | 232           |  \n",
    "| 852             | 2                   | 1                | 35           | 178           |  \n",
    "\n",
    "You will build a linear regression model using these values so you can then predict the price for other houses. For example, a house with 1200 sqft, 3 bedrooms, 1 floor, 40 years old.  \n",
    "\n",
    "Please run the following code cell to create your `X_train` and `y_train` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "X_train=np.array([[2104,5,1,45],  # Training Set Number -1\n",
    "                 [1416,3,2,40], # Training set Number -2 \n",
    "                 [852,2,1,35]])  # Training set Number -3\n",
    " \n",
    "Y_train=np.array([460,232,178])\n",
    "#  We have to treat the Whole Operation Like Two-Dimensional Array i and j \n",
    "print(X_train[1,2]) # Operations of 2-Dimensional Arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the compute_function \n",
    "def compute_function(x,w,b):\n",
    "    f_wb=np.dot(x,w) +b\n",
    "    return f_wb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that here the parameter `x` and `w `passed represents Vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the compute_cost\n",
    "def compute_cost(x,y,w,b):\n",
    "    m=x.shape[0]\n",
    "    cost=0.0\n",
    "    for i in range(m):\n",
    "        temp_i=(np.dot(x[i],w)-y[i])**2\n",
    "        cost += temp_i\n",
    "    cost = cost/(2*m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Calculating the Derivatives Vector \n",
    "def gradient_cal(x,y,w,b):\n",
    "# df_dw --> Will be a vector \n",
    "# df_db --> will be a list\n",
    "\n",
    "# X_train= [[2104,5,1,45](i=0),[1416,3,2,40](i=1), [852,2,1,35](i=2)]\n",
    "# m=3\n",
    "# n=4\n",
    "\n",
    "\n",
    "    df_dw=[]\n",
    "    df_db=0\n",
    "    n=x.shape[1]\n",
    "    m=x.shape[0]\n",
    "    for i in range(m):\n",
    "        common_part = (compute_function(x[i],w,b) -y[i])\n",
    "        for j in range(n):\n",
    "            df_dw +=common_part*x[j]\n",
    "        df_db+=common_part\n",
    "    df_dw=df_dw/m\n",
    "    df_db=df_db/m\n",
    "\n",
    "    return df_dw,df_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Gradient Descent Algorithm\n",
    "def descent_algo(x,y,learning_rate,iterations):\n",
    "\n",
    "    m=x.shape[0]\n",
    "    n=x.shape[1]\n",
    "    w_init = np.random.rand(4)\n",
    "    b_init=0\n",
    "\n",
    "    for i in range(iterations):\n",
    "        temp_w=w_init-learning_rate*gradient_cal(x,y,w_init,b_init)[0]\n",
    "        temp_b=b_init-learning_rate*gradient_cal(x,y,w_init,b_init)[1]\n",
    "        w_init=temp_w\n",
    "        b_init=b_init\n",
    "    return w_init,b_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Values using the gradient Descent Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (0,) (4,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Optimized Values for W(weight): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdescent_algo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m The Optimised Value for b(bias) : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdescent_algo(X_train,Y_train,\u001b[38;5;241m0.1\u001b[39m,\u001b[38;5;241m10000\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 10\u001b[0m, in \u001b[0;36mdescent_algo\u001b[1;34m(x, y, learning_rate, iterations)\u001b[0m\n\u001b[0;32m      7\u001b[0m b_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m---> 10\u001b[0m     temp_w\u001b[38;5;241m=\u001b[39mw_init\u001b[38;5;241m-\u001b[39mlearning_rate\u001b[38;5;241m*\u001b[39m\u001b[43mgradient_cal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb_init\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     11\u001b[0m     temp_b\u001b[38;5;241m=\u001b[39mb_init\u001b[38;5;241m-\u001b[39mlearning_rate\u001b[38;5;241m*\u001b[39mgradient_cal(x,y,w_init,b_init)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     12\u001b[0m     w_init\u001b[38;5;241m=\u001b[39mtemp_w\n",
      "Cell \u001b[1;32mIn[22], line 13\u001b[0m, in \u001b[0;36mgradient_cal\u001b[1;34m(x, y, w, b)\u001b[0m\n\u001b[0;32m     11\u001b[0m     common_part \u001b[38;5;241m=\u001b[39m (compute_function(x[i],w,b) \u001b[38;5;241m-\u001b[39my[i])\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m---> 13\u001b[0m         \u001b[43mdf_dw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommon_part\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     14\u001b[0m     df_db\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mcommon_part\n\u001b[0;32m     15\u001b[0m df_dw\u001b[38;5;241m=\u001b[39mdf_dw\u001b[38;5;241m/\u001b[39mm\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (0,) (4,) "
     ]
    }
   ],
   "source": [
    "print(f\"The Optimized Values for W(weight): {descent_algo(X_train,Y_train,0.1,10000)[0]} The Optimised Value for b(bias) : {descent_algo(X_train,Y_train,0.1,10000)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
